{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data from ROOT using UpROOT\n",
    "\n",
    "_For flat data structures, it's very simple to read in data using uproot,\n",
    "especially when that data can fit in memory. In this example we read a ROOT file\n",
    "in and store the data in a DataFrame. The data is then split 80/20, with the first\n",
    "80 used to form the predicted hypothesis/spectrum, and the last 20 used for validation._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readiness Checklist\n",
    "_Once this checklist is completed, it can be removed and this module is complete_\n",
    "- [x] Read in an arbitrary root file (produced externally)\n",
    "- [ ] Produce multiple 1D PDFs\n",
    "- [ ] Produce a 2D PDF\n",
    "- [ ] Produce a ... 4D PDF?\n",
    "- [x] Mock dataset to fit to a 1D PDF\n",
    "- [ ] Fit to the 2D distribution (extended likelihood)\n",
    "- [ ] Produce uncertainties\n",
    "- [ ] Bias\n",
    "- [ ] Pull\n",
    "- [ ] Are all of these dependencies necessary?\n",
    "- [ ] Move required dependencies to Project.toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "push!(LOAD_PATH, \"../src/\")\n",
    "using Batman\n",
    "import Random: rand\n",
    "using DataFrames\n",
    "using Distributions\n",
    "using StatsPlots; pyplot()\n",
    "using PyPlot\n",
    "import PyCall\n",
    "\n",
    "import KernelDensity: kde, InterpKDE\n",
    "import Interpolations; itp = Interpolations\n",
    "using BenchmarkTools\n",
    "import Distributions: Normal\n",
    "import StatsBase: Histogram, fit\n",
    "import LinearAlgebra: normalize\n",
    "\n",
    "using KernelDensityEstimate\n",
    "using KernelDensityEstimatePlotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from ROOT\n",
    "The data is read in with a simple utility `DataStructures.rootreader`, internally this is stored in a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The expected data is drawn from a bivariate distribution. In 1D these are normal\n",
    "# however, the two variables \"energy\" and \"position\" are highly correlated.\n",
    "\n",
    "# The root files do not exist yet; however, we have a helper python script to create\n",
    "# them. This is not julia because at the moment, uproot writing does not work.\n",
    "PyCall.py\"\"\"exec(open(\"assets/batroot.py\").read())\"\"\"\n",
    "\n",
    "signalMC = DataStructures.rootreader(\"assets/signal.root\", \"bat\")\n",
    "bkgMC = DataStructures.rootreader(\"assets/background.root\", \"bat\")\n",
    "marginalhist(signalMC.energy, signalMC.position, seriescolor=:viridis, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mock data comparison\n",
    "From the distributions package, we will create our own bivariate dataset that is independent of this root file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a root data file using only uproot.\n",
    "signal_truth = 1000\n",
    "bkg_truth = 350*0\n",
    "# Signal first\n",
    "Σ = [[1.0,0.7] [0.7,1.0]]\n",
    "μ = [2.0, 4.0]\n",
    "\n",
    "sigPDF = MvNormal(μ, Σ)\n",
    "# Now bkg\n",
    "Σ = [[1.0,-0.7] [-0.7,1.0]]\n",
    "μ = [3.5, 3.5]\n",
    "\n",
    "bkgPDF = MvNormal(μ, Σ)\n",
    "function mock_dataset()\n",
    "    x_signal = rand(sigPDF, rand(Poisson(signal_truth)))\n",
    "    x_bkg = rand(bkgPDF, rand(Poisson(bkg_truth)))\n",
    "\n",
    "    x = hcat(x_bkg, x_signal)\n",
    "    global data = DataFrame(energy=x[1,:], position=x[2,:])\n",
    "    add_dataset(:data, data)\n",
    "end\n",
    "mock_dataset()\n",
    "marginalhist(data.energy, data.position, seriescolor=:viridis, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF from Histogram\n",
    "Creating a PDF from a dataset can be done when the true underlying distribution is unknown, but simulations exist to estimate this distribution. Many approaches exist to estimate the underlying distribution:\n",
    "1. Kernel Density Estimate\n",
    "2. Interpolation + Extrapolation\n",
    "3. Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data.position, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 KDE\n",
    "sig_kde = KdePDF(signalMC, :energy)\n",
    "bkg_kde = KdePDF(bkgMC, :energy)\n",
    "\n",
    "# 2: Flat interpolation + zero extrapolation\n",
    "bins = collect(-2:0.1:8)\n",
    "sig_itp = HistogramPDF(signalMC, :energy; bins=bins)\n",
    "bkg_itp = HistogramPDF(bkgMC, :energy, bins=bins)\n",
    "\n",
    "sx = collect(-5:0.01:10.0)\n",
    "plt.plot(sx, sig_itp(sx), \".\", label=\"Signal\", color=\"xkcd:blue\")\n",
    "plt.plot(sx, sig_kde(sx), label=\"SignalKDE\", color=\"xkcd:blue\" )\n",
    "plt.plot(sx, bkg_itp(sx), \".\", label=\"Background\", color=\"xkcd:green\")\n",
    "plt.plot(sx, bkg_kde(sx), label=\"BackgroundKDE\", color=\"xkcd:green\" )\n",
    "plt.hist(signalMC.energy, density=true, bins=bins, label=\"Signal Hist\", color=\"xkcd:aqua\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum vs integral\n",
    "dx = 0.1\n",
    "x = collect(-10:dx:10)\n",
    "integral = sum( sig_itp.(x)*dx )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D component fit: Signal v Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put together a custom model to fit to the generated dataset\n",
    "\n",
    "model = CustomModel()\n",
    "\n",
    "## Free parameters\n",
    "s = Parameter(\"signal\"; init=1000.0)\n",
    "b = Parameter(\"bkg\"; init=100.0)\n",
    "\n",
    "## Data counts\n",
    "observation_count = Constant(\"obs\", Float64( size(data.energy,1) ))\n",
    "\n",
    "## Build the PDF functions\n",
    "add_function(:sig_itp, sig_itp)\n",
    "add_function(:bkg_itp, bkg_itp)\n",
    "\n",
    "@addfunction bshape() = @. bkg_itp(data.energy)\n",
    "@addfunction sshape() = @. sig_itp(data.energy)\n",
    "\n",
    "@addfunction spectralpdf(s, b) = begin\n",
    "    -sum(log.(b*bshape() .+ s*sshape() ))\n",
    "end\n",
    "#@addfunction extended(x...) = begin\n",
    "#    sum([x...])\n",
    "#end\n",
    "@addfunction logextend(n, x...) = begin\n",
    "    λ = sum([x...])\n",
    "    λ + n*log(n) - n\n",
    "end\n",
    "\n",
    "## Construct NLL\n",
    "ob1 = NLogPDF(\"spectralpdf\", s, b)\n",
    "ob2 = NLogPDF(\"logextend\", observation_count, s, b)\n",
    "\n",
    "## Include the above in our model\n",
    "add_parameters!(model, [s, b, observation_count])\n",
    "add_nlogpdfs!(model, [ob1, ob2])\n",
    "@show model.lower_bounds\n",
    "println(\"Fitting\")\n",
    "options = Dict(\n",
    "    \"ftol_abs\"=>0,\n",
    "    \"ftol_rel\"=>1e-6,\n",
    ")\n",
    "results = minimize!(model; options=options)\n",
    "#println(\"Profiling\")\n",
    "profile!(\"signal\", results)\n",
    "\n",
    "compute_profiled_uncertainties!(results; σ=1)\n",
    "pretty_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot spectra\n",
    "p = getparam(model, \"signal\")\n",
    "#signal_y = getparam(model, \"signal\").fit * sig_itp(bins) * (bins[2]-bins[1])\n",
    "#bkg_y = getparam(model, \"bkg\").fit * bkg_itp(bins)* (bins[2]-bins[1])\n",
    "signal_y = getparam(model, \"signal\").fit * sig_itp(sx) * (bins[2]-bins[1])\n",
    "bkg_y = getparam(model, \"bkg\").fit * bkg_itp(sx)* (bins[2]-bins[1])\n",
    "plt.plot(sx, signal_y+bkg_y, label=\"Total\", color=\"black\")\n",
    "plt.plot(sx, signal_y, label=\"signal\")\n",
    "plt.plot(sx, bkg_y, label=\"bkg\")\n",
    "plt.hist(data.energy, bins=bins, label=\"Data\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot\n",
    "plt.style.use(\"bat.mplstyle\")\n",
    "\n",
    "hs = x -> x >= 0 ? 1 : 0\n",
    "#profile!(\"Signal\", results; prior=nothing)\n",
    "#uncertainty!(\"Signal\", results )\n",
    "\n",
    "interval_plot(results, \"signal\")\n",
    "plt.savefig(\"profile.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot\n",
    "correlation_plots(results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_plots2(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bias/Pull Testing\n",
    "\n",
    "bias_vector = []\n",
    "pull_vector = []\n",
    "trials = collect(1:10)\n",
    "\n",
    "errors = 0\n",
    "for t in trials\n",
    "    try\n",
    "        mock_dataset()\n",
    "        results = minimize!(model; options=options)\n",
    "        profile!(\"signal\", results)\n",
    "        uncertainty!(\"signal\", results;σ=1)\n",
    "        sig_stats = getparam(model, \"signal\")\n",
    "        bias = sig_stats.fit - signal_truth\n",
    "        if bias >= 0\n",
    "            pull = bias / abs(sig_stats.fit - sig_stats.low)\n",
    "        else\n",
    "            pull = bias / abs(sig_stats.fit - sig_stats.high)\n",
    "        end\n",
    "        push!(bias_vector, bias)\n",
    "        push!(pull_vector, pull)\n",
    "    catch e\n",
    "        errors += 1\n",
    "    end\n",
    "    print(t,\"\\r\")\n",
    "end\n",
    "println(\"Failure rate: \", errors/maximum(trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show mean = sum(bias_vector) / length(bias_vector)\n",
    "plt.hist(bias_vector, bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show mean = sum(pull_vector)/length(pull_vector)\n",
    "@show dev = sqrt(sum((pull_vector.-mean).^2)/length(pull_vector))\n",
    "\n",
    "plt.hist(pull_vector, bins=collect(-3:0.1:3))\n",
    "\n",
    "println(\"Pull distribution: \", mean, \" +- \", dev);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
